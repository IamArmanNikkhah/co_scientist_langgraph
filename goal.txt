To identify the visual, auditory, and interaction features of immersive 360° virtual reality (VR) experiences that most effectively elicit cognitive and neural responses differentiating individuals with mild cognitive impairment (MCI) or early Alzheimer’s disease from cognitively healthy older adults, and to determine which multimodal behavioral and physiological features—including eye gaze, head movement, and prefrontal hemodynamic activity (fNIRS)—best capture those differences.
The project will (1) design and iteratively test 360° video and spatial audio environments that vary in cognitive demand (e.g., attention, navigation, memory recall, emotional salience, and sensory complexity), and (2) analyze behavioral and neural data collected during these tasks to identify feature patterns that reliably distinguish cognitive status.
Participants aged 60–80 from outpatient memory clinics and matched healthy controls will complete the VR tasks while gaze, field-of-view dynamics, and fNIRS signals are recorded. Data-driven statistical and computational analyses will be used to identify the stimulus and response features most sensitive and specific to early cognitive decline, with diagnostic accuracy evaluated against established cognitive assessments (e.g., MoCA, CDR).
Primary objective: Define the key VR content and sensory features that elicit measurable cognitive signatures and establish a set of multimodal digital biomarkers (behavioral + neural) for early detection of Alzheimer’s-related impairment.